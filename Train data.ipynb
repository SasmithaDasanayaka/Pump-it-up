{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_dir = {root_dir}\r\n",
    "train_dir = root_dir + 'clean.csv'\r\n",
    "test_dir = root_dir + 'clean_test.csv'\r\n",
    "\r\n",
    "train = pd.read_csv(train_dir)\r\n",
    "test = pd.read_csv(test_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train.shape,test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#drop unnamed column \r\n",
    "train.drop(train.columns[train.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\r\n",
    "test.drop(test.columns[test.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\r\n",
    "\r\n",
    "target=train.pop('status_group')\r\n",
    "\r\n",
    "# new col to identify test/train data\r\n",
    "train['is_test']=0\r\n",
    "test['is_test']=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train.shape,test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_test = pd.concat([train, test])\r\n",
    "train_test.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_test['funder'] = pd.factorize(train_test['funder'])[0]\n",
    "train_test['installer'] = pd.factorize(train_test['installer'])[0]\n",
    "train_test['scheme_management'] = pd.factorize(train_test['scheme_management'])[0]\n",
    "train_test['extraction_type'] = pd.factorize(train_test['extraction_type'])[0]\n",
    "train_test['management'] = pd.factorize(train_test['management'])[0]\n",
    "# train_test['payment_type'] = pd.factorize(train_test['payment_type'])[0]\n",
    "# train_test['water_quality'] = pd.factorize(train_test['water_quality'])[0]\n",
    "# train_test['quantity'] = pd.factorize(train_test['quantity'])[0]\n",
    "train_test['source'] = pd.factorize(train_test['source'])[0]\n",
    "# train_test['waterpoint_type'] = pd.factorize(train_test['waterpoint_type'])[0]\n",
    "# train_test['basin'] = pd.factorize(train_test['basin'])[0]\n",
    "train_test['region'] = pd.factorize(train_test['region'])[0]\n",
    "train_test['lga'] = pd.factorize(train_test['lga'])[0]\n",
    "train_test['district_code'] = pd.factorize(train_test['district_code'])[0]\n",
    "train_test['operational_year'] = pd.factorize(train_test['operational_year'])[0]\n",
    "len(train_test.basin.unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y1 = pd.get_dummies(train_test.payment_type,prefix = 'payment')\n",
    "y2 = pd.get_dummies(train_test.water_quality,prefix = 'quality')\n",
    "y3 = pd.get_dummies(train_test.quantity,prefix = 'quantity')\n",
    "y4 = pd.get_dummies(train_test.waterpoint_type,prefix = 'waterpoint_type')\n",
    "y5 = pd.get_dummies(train_test.basin,prefix = 'basin')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_test = pd.concat([train_test,y1,y2,y3],axis = 1)\n",
    "train_test.drop(['payment_type','water_quality','quantity','waterpoint_type','basin'],axis =1, inplace=True)\n",
    "\n",
    "df_train = train_test[train_test[\"is_test\"] == 0]\n",
    "df_test = train_test[train_test[\"is_test\"] == 1]\n",
    "\n",
    "df_train.drop([\"is_test\"], axis=1, inplace=True)\n",
    "df_train.drop(['id'],axis=1, inplace=True)\n",
    "df_test.drop([\"is_test\"], axis=1, inplace=True)\n",
    "\n",
    "train_test.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df_train\n",
    "y = target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_fc = RandomForestClassifier(n_estimators=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#from sklearn.svm import SVC\n",
    "#clf = SVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(objective = 'multi:softmax',\n",
    "                      booster = 'gbtree', max_depth = 14,\n",
    "                      nrounds = 'min.error.idx', \n",
    "                      num_class = 4,\n",
    "                      maximize = False, \n",
    "                      eval_metric = 'merror',\n",
    "                      eta = .2,\n",
    "                      colsample_bytree = .4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn=KNeighborsClassifier(n_neighbors=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensembler = VotingClassifier(estimators=[('xg', model), ('rf', random_fc)],weights=[1,2], voting='hard')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(ensembler, X, y, cv=3)\n",
    "\n",
    "# array([0.80328283, 0.80328283, 0.80141414])  0.8173\n",
    "# array([0.8040404 , 0.80479798, 0.80075758])  0.8165\n",
    "# array([0.80838384, 0.8109596 , 0.80752525])  0.8153\n",
    "# array([0.79767677, 0.79782828, 0.79590909])  0.8096\n",
    "# array([0.79828283, 0.79767677, 0.79540404])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ensembler.fit(X,y)\n",
    "X.info()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_fc.fit(X,y)\n",
    "\n",
    "importances = random_fc.feature_importances_\n",
    "importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(X.columns[indices[f]],end=', ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# #for xgboost\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# print(cross_val_score(model, X, y, cv=3))\n",
    "# model.fit(X,y)\n",
    "# importances = model.feature_importances_\n",
    "# importances\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(X.columns[indices[f]],end=', ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "####xg-nrounds=1000-array([ 0.80924242,  0.81217172,  0.81186869])\n",
    "#xg-max_depth=5-array([ 0.76282828,  0.76823232,  0.76994949])\n",
    "#xg-max_depth=30-array([ 0.80772727,  0.80782828,  0.805     ])\n",
    "#random_fc-array([ 0.80479798,  0.80267677,  0.80207071])\n",
    "#xg-nrounds=500-array([ 0.80939394,  0.80828283,  0.80777778])\n",
    "#xg-nrounds=1000-array([ 0.80939394,  0.80828283,  0.80777778])\n",
    "#xg-max_depth=20-array([ 0.8089899 ,  0.80893939,  0.80848485])\n",
    "#xg-max_depth=16-array([ 0.80838384,  0.80984848,  0.80742424])\n",
    "#xg-max_depth=12,nfold=5,array([ 0.80939394,  0.80828283,  0.80777778])\n",
    "#xg-max_depth=12,nfold=6,array([ 0.80939394,  0.80828283,  0.80777778])\n",
    "#xg-max_depth=12,nfold=6,nrounds=1200,early_stopping_rounds = 9-"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test=test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "idx=X_test['id']\n",
    "X_test.drop(['id'],axis=1, inplace=True)\n",
    "y_pred = ensembler.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred['id']=idx\n",
    "y_pred.columns=['status_group','id']\n",
    "y_pred=y_pred[['id','status_group']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"submission_clf_4.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda47702eee39b8497599390ad2c666a2e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}